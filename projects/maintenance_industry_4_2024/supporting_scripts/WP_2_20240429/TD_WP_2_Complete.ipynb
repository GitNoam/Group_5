{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exective summary of Work Package 2\n",
    "\n",
    "## Objectives\n",
    "\n",
    "In this WP, you will work on a given training dataset. Your goal is to develop a fault detection model using the classification algorithms learnt in the class, in order to achieve best F1 score.\n",
    "\n",
    "## Tasks\n",
    "\n",
    "- Task 1: Develop a fault detection model using the unsupervised learning algorithms learnt in the class, in order to achieve best F1 score.\n",
    "- Task 2: With the help of the supporting script, develop a cross-validation scheme to test the performance of the developed classification algorithms.\n",
    "- Task 3: Develop a fault detection model using the classification algorithms learnt in the class, in order to achieve best F1 score.\n",
    "\n",
    "## Delierables\n",
    "\n",
    "- A Jupyter notebook reporting the process and results of the above tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Before starting, please:\n",
    "- Fetch the most up-to-date version of the github repository.\n",
    "- Create a new branch with your name, based on the \"main\" branch and switch to your own branch.\n",
    "- Copy this notebook to the work space of your group, and rename it to TD_WP_2_Your name.ipynb\n",
    "- After finishing this task, push your changes to the github repository of your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1: Unsupervised learning approaches\n",
    "\n",
    "## Implement the statistical testing approach for fault detection\n",
    "\n",
    "In this exercise, we interpret the statistical testing approach for fault detection. The basic idea of statistical testing approach is that we fit a multi-dimensitional distribution to the observation data under normal working condition. Then, when a new data point arrives, we design a hypothesis test to see whether the new data point is consistent with the distribution. If the new data point is consistent with the distribution, we can conclude that the fault is not due to the faulty component.\n",
    "\n",
    "The benefit of this approach is that, to design the detection algrothim, we do not need failed data. Also, the computational time is short as all we need is just to compute the pdf and compare it to a threshold.\n",
    "\n",
    "In this exercise, you need to:\n",
    "- Fit a multi-dimensitional distribution to the training dataset (all normal samples).\n",
    "- Design a fault detection algorithm based on the fitted distribution to detect faulty components.\n",
    "\n",
    "The following block defines a few functions that you can use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from scipy.stats import multivariate_normal\n",
    "\n",
    "\n",
    "def estimateGaussian(X):\n",
    "    '''Given X, this function estimates the parameter of a multivariate Gaussian distribution.'''\n",
    "    mu = np.mean(X, axis=0)\n",
    "    sigma2 = np.var(X, axis=0)\n",
    "    return mu, sigma2\n",
    "\n",
    "\n",
    "def classify(X, distribution, log_epsilon=-100000):\n",
    "    '''Given X, this function classifies each sample in X based on the multivariate Gaussian distribution. \n",
    "       The decision rule is: if the log pdf is less than log_epsilon, we predict 1, as the sample is unlikely to be from the distribution, which represents normal operation.\n",
    "    '''\n",
    "    p = distribution.logpdf(X)\n",
    "    predictions = (p < log_epsilon).astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use the dataset `20240105_164214` as training dataset, as all the samples in this dataset are normal operation. We will use the dataset `20240325_155003` as testing dataset. Let us try to predict the state of motor 1. For this, we first extract the position, temperature and voltage of motor 1 as features (you can change the features if you want). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/weing/Documents/Centrale/Maintenance/Group_5/projects/maintenance_industry_4_2024/supporting_scripts/WP_1')\n",
    "\n",
    "from utility import read_all_csvs_one_test\n",
    "import pandas as pd\n",
    "\n",
    "# Specify path to the dictionary.\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "dictionary_name = '20240105_164214'\n",
    "path = base_dictionary + dictionary_name\n",
    "\n",
    "# Read the data.\n",
    "df_data = read_all_csvs_one_test(path, dictionary_name)\n",
    "\n",
    "# Get the features\n",
    "X_train = df_data[['data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage','data_motor_2_voltage','data_motor_3_voltage','data_motor_4_voltage']]\n",
    "\n",
    "# We do the same to get the test dataset.\n",
    "dictionary_name = '20240325_155003'\n",
    "path = base_dictionary + dictionary_name\n",
    "\n",
    "# Read the data.\n",
    "df_data = read_all_csvs_one_test(path, dictionary_name)\n",
    "\n",
    "# Get the features\n",
    "X_test = df_data[['data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage','data_motor_2_voltage','data_motor_3_voltage','data_motor_4_voltage']]\n",
    "y_test = df_data['data_motor_1_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please design your algorithm below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9156644618159951\n",
      "F1: 0.7396751740139212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "\n",
    "# First, we need to fit a MVN distribution to the normal samples.\n",
    "# Put your code here.\n",
    "mu, sigma2 = estimateGaussian(X_train)\n",
    "\n",
    "# Construct a multivariate Gaussian distribution to represent normal operation.\n",
    "distribution = multivariate_normal(mean=mu, cov=np.diag(sigma2))\n",
    "\n",
    "# Now, let's try to predict the labels of the test set X_test.\n",
    "# Put your code here.\n",
    "y_pred = classify(X_test, distribution,-10**5.8)\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discussions:**\n",
    "- Can you please try to improve the performance of this approach?\n",
    "    - For example, by normalizating the data?\n",
    "    - By smoothing the data?\n",
    "    - By reducing feature number?\n",
    "    - etc.\n",
    "- The parameter log_epsilon defines the threshold we use for making classification. What happens if you change it?\n",
    "- Could you discuss how we should get the best value for this parameter?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9156644618159951\n",
      "F1: 0.7396751740139212\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score,accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "#Normalization\n",
    "\n",
    "scaler=MinMaxScaler()\n",
    "X_train_norm=scaler.fit_transform(X_train)\n",
    "X_test_norm=scaler.transform(X_test)\n",
    "# First, we need to fit a MVN distribution to the normal samples.\n",
    "# Put your code here.\n",
    "mu, sigma2 = estimateGaussian(X_train_norm)\n",
    "\n",
    "# Construct a multivariate Gaussian distribution to represent normal operation.\n",
    "distribution = multivariate_normal(mean=mu, cov=np.diag(sigma2))\n",
    "\n",
    "# Now, let's try to predict the labels of the test set X_test.\n",
    "# Put your code here.\n",
    "y_pred = classify(X_test_norm, distribution,-10**5.8)\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 0 0 0]\n",
      "Accuracy: 0.9164161154539988\n",
      "F1: 0.7421150278293135\n"
     ]
    }
   ],
   "source": [
    "#Smoothing\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# First, we need to fit a MVN distribution to the normal samples.\n",
    "# Put your code here.\n",
    "\n",
    "X_train_smoothed=X_train.rolling(window=20, min_periods=1).mean()\n",
    "X_test_smoothed=X_test.rolling(window=20, min_periods=1).mean()\n",
    "\n",
    "\n",
    "mu, sigma2 = estimateGaussian(X_train_smoothed)\n",
    "\n",
    "# Construct a multivariate Gaussian distribution to represent normal operation.\n",
    "distribution = multivariate_normal(mean=mu, cov=np.diag(sigma2))\n",
    "\n",
    "# Now, let's try to predict the labels of the test set X_test.\n",
    "# Put your code here.\n",
    "y_pred = classify(X_test_smoothed, distribution,-10**7)\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(\"F1:\", accuracy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local outiler factor (LOF)\n",
    "\n",
    "The local outlier factor (LOF) algorithm computes the local density deviation of a given data point with respect to its neighbors. It considers as outliers the samples that have a substantially lower density than their neighbors. You can easiliy implement LOF in scikit-learn ([tutorial](https://www.datatechnotes.com/2020/04/anomaly-detection-with-local-outlier-factor-in-python.html)).\n",
    "\n",
    "Please implement local outlier factor (LOF) algorithm on the dataset of `20240325_155003`. You can try first to detect the failure of motor 1 using this model. Please calculate the accuracy score of your prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data_motor_1_position</th>\n",
       "      <th>data_motor_1_temperature</th>\n",
       "      <th>data_motor_1_voltage</th>\n",
       "      <th>data_motor_1_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>487</td>\n",
       "      <td>38</td>\n",
       "      <td>7044</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>487</td>\n",
       "      <td>39</td>\n",
       "      <td>7028</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>487</td>\n",
       "      <td>39</td>\n",
       "      <td>7037</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>487</td>\n",
       "      <td>39</td>\n",
       "      <td>7055</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487</td>\n",
       "      <td>39</td>\n",
       "      <td>7053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   data_motor_1_position  data_motor_1_temperature  data_motor_1_voltage  \\\n",
       "0                    487                        38                  7044   \n",
       "1                    487                        39                  7028   \n",
       "2                    487                        39                  7037   \n",
       "3                    487                        39                  7055   \n",
       "4                    487                        39                  7053   \n",
       "\n",
       "   data_motor_1_label  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utility import read_all_csvs_one_test\n",
    "\n",
    "\n",
    "# Define the path to the folder 'collected_data'\n",
    "base_dictionary = 'C:/Users/weing/Documents/Centrale/Maintenance/Group_5/projects/maintenance_industry_4_2024/dataset/training_data/20240325_155003/'\n",
    "\n",
    "#Choose which motor to study\n",
    "motor_num=input()\n",
    "\n",
    "# Read all the data\n",
    "df_base = read_all_csvs_one_test(base_dictionary)\n",
    "df = df_base[[f'data_motor_{motor_num}_position',  f'data_motor_{motor_num}_temperature',  f'data_motor_{motor_num}_voltage',f'data_motor_{motor_num}_label']]\n",
    "df.size\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 ... 1 1 1]\n",
      "Accuracy: 0.19422730006013228\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.datasets import make_blobs\n",
    "from numpy import quantile, where, random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=600, contamination=.001)\n",
    "\n",
    "\n",
    "y_pred = lof.fit_predict(X_test)\n",
    "\n",
    "\n",
    "lofs_index = where(y_pred==-1)\n",
    "values = X_test.iloc[lofs_index]\n",
    "\n",
    "\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "plt.scatter(X_test.iloc[:,0], X_test.iloc[:,1])\n",
    "plt.scatter(values.iloc[:,0],values.iloc[:,1], color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalOutlierFactor()\n",
      "-1.9113600795793515\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[84], line 34\u001b[0m\n\u001b[0;32m     31\u001b[0m values \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39miloc[index]\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate F1 score of the prediction.\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, accuracy)\n\u001b[0;32m     38\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m0\u001b[39m], df\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:214\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m    210\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m    211\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    212\u001b[0m         )\n\u001b[0;32m    213\u001b[0m     ):\n\u001b[1;32m--> 214\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[0;32m    221\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[0;32m    224\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1239\u001b[0m, in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1071\u001b[0m     {\n\u001b[0;32m   1072\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1097\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1098\u001b[0m ):\n\u001b[0;32m   1099\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[0;32m   1100\u001b[0m \n\u001b[0;32m   1101\u001b[0m \u001b[38;5;124;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1237\u001b[0m \u001b[38;5;124;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[0;32m   1238\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1240\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1241\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1245\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1246\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1247\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1413\u001b[0m, in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1251\u001b[0m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[0;32m   1252\u001b[0m     {\n\u001b[0;32m   1253\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m: [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray-like\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse matrix\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     zero_division\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwarn\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1281\u001b[0m ):\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \n\u001b[0;32m   1284\u001b[0m \u001b[38;5;124;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;124;03m    0.38...\u001b[39;00m\n\u001b[0;32m   1411\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1413\u001b[0m     _, _, f, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1414\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1415\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1416\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1417\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1418\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1419\u001b[0m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1420\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mf-score\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1422\u001b[0m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:187\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    185\u001b[0m global_skip_validation \u001b[38;5;241m=\u001b[39m get_config()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mskip_parameter_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[1;32m--> 187\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    189\u001b[0m func_sig \u001b[38;5;241m=\u001b[39m signature(func)\n\u001b[0;32m    191\u001b[0m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1724\u001b[0m, in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[0;32m   1566\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[0;32m   1567\u001b[0m \n\u001b[0;32m   1568\u001b[0m \u001b[38;5;124;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1721\u001b[0m \u001b[38;5;124;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[0;32m   1722\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1723\u001b[0m zero_division_value \u001b[38;5;241m=\u001b[39m _check_zero_division(zero_division)\n\u001b[1;32m-> 1724\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1726\u001b[0m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[0;32m   1727\u001b[0m samplewise \u001b[38;5;241m=\u001b[39m average \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1518\u001b[0m, in \u001b[0;36m_check_set_wise_labels\u001b[1;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[0;32m   1516\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m y_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulticlass\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m   1517\u001b[0m             average_options\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msamples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1518\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1519\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget is \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m but average=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1520\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchoose another average setting, one of \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (y_type, average_options)\n\u001b[0;32m   1521\u001b[0m         )\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pos_label \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1523\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1524\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote that pos_label (set to \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m) is ignored when \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maverage != \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m (got \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m). You may use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1528\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1529\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted']."
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.datasets import make_blobs\n",
    "from numpy import quantile, where, random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=.01)\n",
    " \n",
    "y_pred = lof.fit_predict(df)\n",
    "\n",
    "\n",
    "lofs_index=where(y_pred==-1)[0]\n",
    "values = df.iloc[list(lofs_index),:]\n",
    "\n",
    "\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "plt.scatter(values.iloc[:,0],values.iloc[:,1], color='r')\n",
    "plt.show()\n",
    "\n",
    "model = LocalOutlierFactor(n_neighbors=20) \n",
    "print(model)  \n",
    "model.fit_predict(df) \n",
    " \n",
    "lof = model.negative_outlier_factor_\n",
    "thresh = quantile(lof, .03)\n",
    "print(thresh) \n",
    " \n",
    "index = where(lof<=thresh)\n",
    "values = df.iloc[index]\n",
    "\n",
    "# Calculate F1 score of the prediction.\n",
    "accuracy = f1_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "\n",
    "plt.scatter(df.iloc[:,0], df.iloc[:,1])\n",
    "plt.scatter(values.iloc[:,0],values.iloc[:,1], color='r')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score: 0.16897173782321107\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Charger le jeu de donnes\n",
    "data=df\n",
    "\n",
    "# Supprimer les colonnes inutiles ou non pertinentes\n",
    "# data = data.drop(columns=['colonne_inutile_1', 'colonne_inutile_2', ...])\n",
    "\n",
    "# Slectionner les colonnes pertinentes pour l'analyse LOF (peut-tre toutes les colonnes sauf la colonne de timestamp)\n",
    "X = data.iloc[:, 1:]  # Exclure la premire colonne (timestamp) si elle existe\n",
    "\n",
    "# Initialiser et ajuster le modle LOF\n",
    "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
    "lof.fit(X)\n",
    "\n",
    "# Prdire les valeurs aberrantes\n",
    "y_pred = lof.fit_predict(X)\n",
    "\n",
    "# Supposons que vous ayez des tiquettes pour les checs du moteur 1 dans une colonne 'motor1_failure'\n",
    "# Comparez les prdictions avec les tiquettes relles et calculez l'exactitude\n",
    "ground_truth_labels = data['data_motor_1_label']\n",
    "accuracy = accuracy_score(ground_truth_labels, y_pred)\n",
    "print(\"Accuracy score:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2 Develop a cross validation pipeline to evaluate the performance of the model.\n",
    "\n",
    "The idea of cross validation is to split the data into k subsets and use one of them as the test set and the rest as the training set. The performance of the model is evaluated only on the test dataset, while the model is trained on the training dataset. By doing this, we ensure that the evaluation of the model is independent from the training of the model. Therefore, we can detect if the model is overfitted.\n",
    "\n",
    "## k-fold cross validation\n",
    "\n",
    "Here, we use motor 1 as an example to develop a pipeline for cross validation. Below, you have a script that read the data, extract features and get the labels.\n",
    "\n",
    "1. Use sk-learn to split the data into training and testing sets, using a k-fold cross validation with k=5. (Hint: This is a routine task which can be answered easily by language models like chatgpt. You can try prompt like this: `Generate a code in python to split the data X and y into training and testing sets, using a k-fold cross validation with k=5.`)\n",
    "2. Then, train a basic logistic regression model, without hyper-parameter tuning on the training set, and use the testing set to evaluate the performance of the model (calculate accuracy, precision, recall, and F1 score). \n",
    "3. Finally, train a logistic regression model, but use the entire dataset X and y as training data. Then, use the trained model to predict the labels of the same dataset (X). Compare the results with the previous step, and discuss why we should use cross validation to evaluate the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\compat\\_optional.py:142\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 142\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\importlib\\__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m base_dictionary \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../dataset/training_data/\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Read all the data\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m df_data \u001b[38;5;241m=\u001b[39m \u001b[43mread_all_test_data_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dictionary\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# Extract the features for motor 1: You should replace the features with the ones you have selected in WP1.\u001b[39;00m\n\u001b[0;32m     14\u001b[0m X \u001b[38;5;241m=\u001b[39m df_data[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_motor_1_position\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_motor_1_temperature\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_motor_1_voltage\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[1;32mC:\\Users/weing/Documents/Centrale/Maintenance/Group_5/projects/maintenance_industry_4_2024/supporting_scripts/WP_1\\utility.py:50\u001b[0m, in \u001b[0;36mread_all_test_data_from_path\u001b[1;34m(base_dictionary, pre_processing, is_plot)\u001b[0m\n\u001b[0;32m     47\u001b[0m     df_data \u001b[38;5;241m=\u001b[39m df_data\u001b[38;5;241m.\u001b[39mreset_index(drop\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# Read the test conditions\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m df_test_conditions \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_dictionary\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTest conditions.xlsx\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Visulize the data\u001b[39;00m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m selected_sequence_idx \u001b[38;5;129;01min\u001b[39;00m path_list:\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:478\u001b[0m, in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[0;32m    477\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m--> 478\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[0;32m    480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    483\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_base.py:1513\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[0;32m   1511\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[1;32m-> 1513\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\excel\\_openpyxl.py:548\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[1;34m(self, filepath_or_buffer, storage_options)\u001b[0m\n\u001b[0;32m    533\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m    534\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    535\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    536\u001b[0m     filepath_or_buffer: FilePath \u001b[38;5;241m|\u001b[39m ReadBuffer[\u001b[38;5;28mbytes\u001b[39m],\n\u001b[0;32m    537\u001b[0m     storage_options: StorageOptions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    538\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    540\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[0;32m    541\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m    {storage_options}\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    549\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(filepath_or_buffer, storage_options\u001b[38;5;241m=\u001b[39mstorage_options)\n",
      "File \u001b[1;32mc:\\Users\\weing\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\compat\\_optional.py:145\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[1;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m    144\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 145\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    148\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'C:/Users/weing/Documents/Centrale/Maintenance/Group_5/projects/maintenance_industry_4_2024/supporting_scripts/WP_1')\n",
    "\n",
    "from utility import read_all_test_data_from_path\n",
    "import pandas as pd\n",
    "\n",
    "# Specify path to the dictionary.\n",
    "# Define the path to the folder 'collected_data'\n",
    "base_dictionary = '../../dataset/training_data/'\n",
    "# Read all the data\n",
    "df_data = read_all_test_data_from_path(base_dictionary)\n",
    "\n",
    "# Extract the features for motor 1: You should replace the features with the ones you have selected in WP1.\n",
    "X = df_data[['data_motor_1_position', 'data_motor_1_temperature', 'data_motor_1_voltage']]\n",
    "# Get the label\n",
    "y = df_data['data_motor_1_label']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write your discussions here:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3: Develop classification-based fault detection models\n",
    "\n",
    "In this task, you are supposed to experiment different classification-based fault detection models to get best F1 score. Please use the 5-fold cross-validation to calculate the best F1 score. You are free to try different models, whether they are discussed in the class or not. To simply your work, you can use the models existed in [scikit-learn](https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "Please report all the models you tried, how to you tune their hyperparameters, and the corresponding F1 score. Please note that if you would like to tune the hyperparameter, you can use the `GridSearchCv` function in scikit-learn, but you should use it only on the training dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of the results\n",
    "\n",
    "Please add a table in the end, summarying the results from all the models (including the unsupervised learning models). Please write a few texts to explain what is the best model you got, its performance, and how could you further improve it.\n",
    "\n",
    "| Model   | Accuracy | Precision | Recall | F1   |\n",
    "|---------|----------|-----------|--------|------|\n",
    "| Model 1 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 2 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n",
    "| Model 3 |   XX.X%  |   XX.X%   |  XX.X% | XX.X%|\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
